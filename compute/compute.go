package compute

import (
//   lmdb "github.com/szferi/gomdb"
)

/*

 The compute code processes a very simple bytecode language. The language provides codes for performing very
 specific operations on data in order to find matching rows. The compute server only processes predicates,
 it does not attempt to perform extractions. Instead, it just keeps track of rows that match.

 Predicate matching works like this:

 1. For each expression a bit is reserved.
 2. For each term a bit pattern is generated.
 3. During evaluation of each row, bits are set to true for each expression evaluating to true.
 4. The generated bit patterns are compared against the bits set by evaluation. As soon as any pattern
    matches we select the row. If we evaluate all expressions without a bit pattern match then the row
    does not match the selection criteria.

 In theory this lets us evaluate each expression once, even though the expression may be present multiple times
 in the query.

 For example:

 SELECT * FROM test WHERE (c1 > 5 AND c2='train') OR (c1 < 2 AND c2='train');

 Granted, this expression could be rewritten more efficiently, but it servers to illustrate a point. Expressions
 cannot always be rewritten in a simple way, or the expressions may be generated by code and the user may never
 have an opportunity to optimize the query.

 In this case we have two terms:
   1. (c1>5 AND c2='train')
   2. (c1<2 AND c2='train')

 There are only three expressions:
   1. c1>5
   2. c1<2
   3. c2='train'

 In this case we might assign the bit indexes to 0, 1, and 2 respectively. So the bit patterns we expect to see
 for each term are:
   1. 101
   2. 110

 If we evaluate the expressions against (c1=9, c2='train'), (c1=1, c2='train'), and (c1=1, c2='plane'):
   1. 101
   2. 110
   3. 010

 What about:

 SELECT * FROM test WHERE (c1 < 2 AND c2='train') OR (c2='plane');

 The bit patterns should be:
   1. 011
   2. 100

 Evaluated against our previous example row:
   1. 001
   2. 011
   3. 101

 Now, this is interesting because we got an additional bit we weren't expecting in the second term. We can't
 perform an exact match because of the additional bits. We don't want to reset them in every situation though,
 because that undermines the entire purpose of the feature. Instead, we just need to mask the result with
 the bits that we care about. Which also happens to be the bit pattern for the term.

 So the compare operation becomes something more like:

   match := (evaluation & pattern) == pattern;

 Using the masked version of the data hides the 'spurious' result and allows us to perform a perfect match.

 What about processing logical inversions? This method only allows us to deal with true results, not explicit
 false results. For example:

 SELECT * FROM test WHERE NOT (c1 > 5 AND c2='train') OR (c2='plane');

 This would fail to evaluate correctly, since what we really want are to see two false values on the left,
 or just one true value on the right. We can't just invert the pattern because we want to see the results
 of those bits. We need them to be checked, and to be false. The solution is fairly obvious: just introduce
 a third value that contains the desired fields.

 The bit pattern and usage masks should be:
   1. 000 / 011
   2. 100 / 100

 Then we proceed as above, with one slight change:

  match := (evaluation & usage_mask) == pattern

 This provides us with the ability to select on the fields we care about, and to test for logical inclusion
 or exclusion.

 What about multiple levels of predicates, like this:

 SELECT * FROM test WHERE ((c1 > 5 AND c2='train') OR (c1 < 2 AND c2='train')) AND
                          ((c1!=0 AND c1!=10) OR (c1!=0 AND c1!=20));

 The 'AND' pieces are simple: we just bitwise-or together the bits in the pattern and it works. The problem is the 'OR'
 sections. On the one hand, we don't need to evaluate all of the OR terms that occur at the same level. We just need to
 evaluate them until one is true. On the other hand, we can't combine the bits of two OR terms because it's entirely
 likely that all of the bits of the two terms won't be evaluated. Consequently, we at least need to keep a usage mask
 for each OR term.

 That means we need to provide for a general expression solver, and we need to provide byte code that can encode
 general expressions. Thus we have the eon virtual machine.

 The machine has an infinite number of registers. The registers hold typed values. An instruction generally writes it's
 result back to a register.

 Binary operations:
 byte:operation byte:type ushort:dest_register ushort:source_register

 Load/Store operations:
 byte:operation byte:type ushort:dest_or_source_register uint:column

 Context operations:
 byte:operation ushort:register uint:offset

 Literal operations:
 byte:operation byte:type ushort:dest_register uint:offset_or_data

 Branch operations:
 byte:operation ushort:register uint:offset

 For context operations there are two possible data components: the register where the value comes from, and an offset into
 the data page associated with the code. For operations like ChooseTable, the register contains an object identifier that should
 be loaded as the active table. ChooseRow is similar, except that it uses the internal row_id, whatever that is.

 For literal operations, if the literal value is small enough to fit in the 32-bit offset_or_data value, then the value is
 stored there. The operation is encoded as a 'load_literal'. If the 'type' is a 64-bit integer, then if the value can be encoded in
 32-bits it will also be stored directly. In all other cases the offset_or_data parameter references an offset into the binary
 data page associated with the code. The operation is encoded as 'load_literal_indirect' The operation 'load_parameter' is used to
 load a parameterized value for pre-compiled queries. That way if we store the compiled query we can simply refer to a parameter
 and avoid having to re-write any part of the

 The predicate above could be encoded like this:

 term1:
 r0 = load int c1
 r1 = load_literal int 5
 r2 = r0 gt r1
 branch_if_false r5 => term2
 r3 = load str c2
 r4 = load_literal_indirect str 0 ; the only literal in the data space is 'train' which starts at offset 0.
 r5 = r3 eq r4
 branch_if_false r5 => term2
 branch => term4

 term2:
 r7 = load_literal int 2
 r8 = r0 lt r7
 branch_if_false r8 => failed
 r9 = r8 and r5
 branch_if_false r9 => failed
 branch => term4

 term4:
 r10 = load_literal int 0
 r11 = r0 ne r10
 branch_if_false r11 => failed
 r12 = load_literal int 10
 r13 = r0 ne r12
 branch_if_false r13 => term5
 branch => passed

 term5:
 r14 = load_literal int 20
 r15 = r0 ne r14
 branch_if_false r15 => failed
 branch => passed

 failed:
 fail
 
 passed:
 pass
 

 */

type Evaluator interface {
   Execute(steps int)
}

type Request struct {
   Cmd int
}

func compute_server(c chan *Request) {
	return;
}

func Start() (chan *Request) {
   c := make(chan *Request, 100)
   go compute_server(c)
   return c
}



